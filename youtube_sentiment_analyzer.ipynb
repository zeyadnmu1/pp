{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# YouTube Sentiment Analyzer \u2014 Full Workflow\nThis notebook performs EDA, training, evaluation, and model export."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd, numpy as np, matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nimport joblib\n\nplt.rcParams.update({'figure.figsize': (8,5)})\ndf = pd.read_csv('../../data/youtube/comments.csv')\ndf.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Class Distribution"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "df['label'].value_counts().plot(kind='bar')\nplt.title('Sentiment Class Distribution'); plt.xlabel('label'); plt.ylabel('count'); plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Length Histogram"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "df['len'] = df['text'].astype(str).str.len()\ndf['len'].plot(kind='hist', bins=30)\nplt.title('Comment Length Distribution'); plt.xlabel('length'); plt.ylabel('freq'); plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Train/Test Split & Model"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "X = df['text'].astype(str)\ny = df['label'].astype('category')\nXtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\npipe = Pipeline([('tfidf', TfidfVectorizer(max_features=30000, ngram_range=(1,2))),\n                 ('clf', LinearSVC())])\ngrid = GridSearchCV(pipe,\n                    {'tfidf__max_df':[0.9,1.0], 'tfidf__min_df':[1,3], 'clf__C':[0.5,1.0,2.0]},\n                    scoring='f1_macro', cv=3, n_jobs=-1)\ngrid.fit(Xtr, ytr)\npred = grid.best_estimator_.predict(Xte)\nprint('Best params:', grid.best_params_)\nprint(classification_report(yte, pred))\nprint(confusion_matrix(yte, pred))"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Export Model"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "joblib.dump(grid.best_estimator_, '../../models/youtube/model.joblib')\nprint('Saved ../../models/youtube/model.joblib')"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}